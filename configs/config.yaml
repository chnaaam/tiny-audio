# Main configuration
defaults:
  - data: loquacious
  - training: production
  - _self_

# Model configuration (must match ASRConfig parameter names)
model:
  # audio_model_id: openai/whisper-large-v3-turbo
  audio_model_id: openai/whisper-large-v2
  # text_model_id: HuggingFaceTB/SmolLM3-3B
  text_model_id: Qwen/Qwen3-0.6B
  system_prompt: "/no_think /system_override"
  projector_type: mlp # Options: mlp, mosa, moe, qformer

  # Projector settings
  projector_pool_stride: 4
  projector_hidden_dim: null

  # MoE settings (for moe/mosa projector types)
  num_experts: 4
  num_experts_per_tok: 2
  router_aux_loss_coef: 0.01

  # Generation settings
  max_new_tokens: 256

# Hydra output directories
hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    chdir: true

# Early stopping (set patience to enable)
early_stopping:
  patience: null
  threshold: 0.0

verbose: false
